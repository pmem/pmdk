name: PMEM Benchmark

on:
  workflow_dispatch:
    inputs:
      reference_ref:
        type: string
        default: master
      rival_ref:
        type: string
        default: stable-2.0
  push: # XXX

# XXX missing in Ansible files
# sudo dnf install numactl python3-pip -y
# pip install --user pandas

jobs:
  prep:
    name: Prepare ${{ matrix.ROLE }}
    runs-on: [self-hosted, benchmark]
    strategy:
      matrix:
        include:
          - ROLE: reference
            REF: master # XXX ${{ inputs.reference_ref }}
          - ROLE: rival
            REF: stable-2.0 # XXX ${{ inputs.rival_ref }}
          - ROLE: runtime
            REF: ''
    permissions:
      contents: read
    steps:
      - name: Clone the git repo (libraries)
        uses: actions/checkout@v4
        with:
          ref: ${{ matrix.REF }}
          fetch-depth: 1
          path: ${{ matrix.ROLE }}

      - name: Build libraries
        working-directory: ${{ matrix.ROLE }}
        run: make -j


  run:
    name: Run perf.cfg ${{ matrix.SCENARIO }}
    runs-on: [self-hosted, benchmark]
    needs: prep
    strategy:
      matrix:
        SCENARIO:
          - obj_tx_alloc_small_v_thread
          - obj_pmalloc_small_v_threads
          - obj_rbtree_map_insert
          - obj_hashmap_tx_map_insert
    steps:
      - name: Benchmark
        uses: ./runtime/.github/actions/pmem_benchmark_run
        with:
          runtime_dir: ./runtime/
          reference: ../reference/src/nondebug
          rival: ../rival/src/nondebug
          config: perf
          scenario: ${{ matrix.SCENARIO }}


  repack:
    name: Repack
    runs-on: ubuntu-latest
    needs: run
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: csvs

      - name: Upload all as a single artifact
        uses: actions/upload-artifact@v4
        with:
          name: perf__all
          path: csvs/**/*
